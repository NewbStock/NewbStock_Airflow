name: Deploy DAGs to Airflow through Bastion

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Set up SSH
      uses: webfactory/ssh-agent@v0.5.3
      with:
        ssh-private-key: ${{ secrets.BASTION_SSH_PRIVATE_KEY }}

    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_DEFAULT_REGION }}

    - name: Upload DAG files to S3
      run: |
        aws s3 sync dags/ s3://team-won-2-dags-bucket/  --delete

    - name: Sync DAGs to Airflow through Bastion
      run: |
        # Bastion Host를 통해 Private Subnet의 Airflow 서버에 SSH 터널링 설정
        ssh -o StrictHostKeyChecking=no -A -i ${{ secrets.AIRFLOW_SSH_PRIVATE_KEY }} ubuntu@13.209.247.212 \
          ssh -o StrictHostKeyChecking=no ubuntu@10.0.143.22 \
          'aws s3 sync s3://team-won-2-dags-bucket/ /home/ubuntu/newbstock_airflow/dags --delete'
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: 'ap-northeast-2'
