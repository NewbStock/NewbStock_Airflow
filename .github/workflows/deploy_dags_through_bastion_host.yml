name: Deploy DAGs to Airflow through Bastion

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Save Bastion SSH Key
      run: |
        echo "${{ secrets.BASTION_SSH_PRIVATE_KEY }}" > newbstock-Bastion-Host.pem
        chmod 600 newbstock-Bastion-Host.pem

    - name: Save Airflow SSH Key
      run: |
        echo "${{ secrets.AIRFLOW_SSH_PRIVATE_KEY }}" > newbstock-airflow-server.pem
        chmod 600 newbstock-airflow-server.pem

    - name: Set up SSH agent and add keys
      uses: webfactory/ssh-agent@v0.5.3
      with:
        ssh-private-key: |
          ${{ secrets.BASTION_SSH_PRIVATE_KEY }}

    - name: Add Airflow SSH Key to Agent
      run: |
        ssh-add newbstock-airflow-server.pem

    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ secrets.AWS_DEFAULT_REGION }}

    - name: Upload DAG files to S3
      run: |
        aws s3 sync . s3://team-won-2-dags-bucket/  --delete
  
    - name: Sync DAGs to Airflow through Bastion
      run: |
        # Bastion Host를 통해 Private Subnet의 Airflow 서버에 SSH 터널링 설정
          ssh -o StrictHostKeyChecking=no -i newbstock-Bastion-Host.pem -A ubuntu@13.209.247.212 \
          ssh -o StrictHostKeyChecking=no -i newbstock-airflow-server.pem ubuntu@10.0.143.22 \
          'aws s3 sync s3://team-won-2-dags-bucket/ /home/ubuntu/newbstock_airflow/dags --delete'
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: 'ap-northeast-2'
